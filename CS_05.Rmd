---
title: "Sports Analytics (Regularization and DecisionTree based approaches for Regression problems)"
author: "Mohammad Ali Momen"
date: "05/06/2023"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 4
    number_sections: true
    self_contained: true
    code_download: true
    code_folding: show
    df_print: paged
  md_document:
    toc: true
    toc_depth: 2
    toc_float: true
    number_sections: true
    variant: markdown_github
  html_notebook: default
  pdf_document: default
  word_document: default
---

```{css, echo=FALSE}
pre {
  max-height: 300px;
  overflow-y: auto;
}

pre[class] {
  max-height: 200px;
}
```

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, attr.source = '.numberLines')
```

***

**Data Analysis methodology**: CRISP-DM

**Dataset**: Hitters dataset (Major League Baseball Data from the 1986 and 1987 seasons in US)

**Case Goal**: Annual Salary prediction of each Player in 1987 base on his performance in 1986

***

# Required Libraries
```{r}
library('glmnet')
library('rpart')
library('rpart.plot')
library('randomForest')
```

***

# Read Data from File
```{r}
load('case4_dataset_v1.RData')  # pre-processed Data
dim(data2)  # 263 records, 19 variables
```

***

# Business Understanding

* know business process and issues
* know the context of the problem
* know the order of numbers in the business

***

# Data Understanding
## Data Inspection 
Data Understanding from Free Perspective

### Dataset variables definition
```{r}
colnames(data2)
```

> KPI (Key Performance Indicator) variables in 1986

* **Hits**:       Number of hits in 1986
* **HmRun**:      Number of home runs in 1986
* **Runs**:       Number of runs in 1986
* **RBI**:        Number of runs batted in in 1986
* **Walks**:      Number of walks in 1986
* **PutOuts**:    Number of put outs in 1986
* **Assists**:    Number of assists in 1986
* **Errors**:     Number of errors in 1986

> KPI variables in whole career life

* **Years**:      Number of years in the major leagues
* **CAtBat**:     Number of times at bat during his career
* **CHits**:      Number of hits during his career
* **CHmRun**:     Number of home runs during his career
* **CRuns**:      Number of runs during his career
* **CRBI**:       Number of runs batted in during his career
* **CWalks**:     Number of walks during his career

> Categorical variables

* **League**:     A factor with levels A and N indicating player's league at the end of 1986 (american league|national league)
* **Division**:   A factor with levels E and W indicating player's division at the end of 1986 (west|east)
* **NewLeague**:  A factor with levels A and N indicating player's league at the beginning of 1987
* **Name**:       name of players

> Outcome variable

* **Salary**:     1987 annual salary on opening day in thousands of dollars


# Data Exploring
Data Understanding from Statistical Perspective

### Overview of Dataframe
```{r}
class(data2)
head(data2)
tail(data2)
str(data2)
summary(data2)
```

***


# Data PreProcessing
## Divide Dataset into Train and Test randomly
```{r}
head(train)
dim(train)  # 18 predictor variables
str(train)

head(test)
dim(test)
str(test)
```


# Modeling

Results of 4 created models:

1. Linear Regression with all 18 variables
2. BestSubSelection base on statistical indexes (BIC, CP, Adjusted-R2)
3. BestSubSelection base on k-fold cross validation
4. BestSubSelection with trimmed data

```{r}
models_comp  # models comparison
```

## Model 5: Ridge Regression
```{r}
x <- model.matrix(Log_Salary ~ . - Salary, data = train)[,-1]  # remove intercept
y <- train$Log_Salary

lambda_ridge_grid <- 10 ^ seq(10, -2, length.out = 100)
lambda_ridge_grid

ridgereg_1 <- glmnet::glmnet(x, y, alpha = 0, lambda = lambda_ridge_grid)
dim(coef(ridgereg_1))  # 19 coefficients (18 predictors + 1 intercept) in 100 iteration (different lambdas)

plot(ridgereg_1, xvar = 'lambda')  # plot Regression Coefficients vs. Log lambda

ridgereg_1$lambda[50]  # lambda value with index 50
coef(ridgereg_1)[,50]  # retrieve one of Regressions Coefficients (Regression Coefficients for lambda 11497.57)
```

k-fold cross validation approach to choose the best model (select the best lambda)
```{r}
set.seed(1234)
ridge_cv <- cv.glmnet(x, y, alpha = 0, nfolds = 10, lambda = lambda_ridge_grid)
ridge_cv

ridge_cv$cvm  # the mean cross-validated error (per every lambda)
ridge_cv$cvsd  # estimate of standard deviation error of cvm
ridge_cv$lambda.min  # value of lambda that gives the minimum cvm

ridgereg_2 <- glmnet(x, y, alpha = 0, lambda = ridge_cv$lambda.min)
coef(ridgereg_2)  # coefficients of regression with best lambda value
```

## Model 6: LASSO Regression
```{r}
lassoreg_1 <- glmnet(x, y, alpha = 1, lambda = lambda_ridge_grid)
dim(coef(lassoreg_1))

plot(lassoreg_1, xvar = 'lambda')  # plot Regression Coefficients vs. Log lambda

lassoreg_1$lambda[90]  # lambda value with index 90
coef(lassoreg_1)[,90]  # retrieve one of Regression Coefficients (Regression Coefficients for lambda 0.1629751
```

k-fold cross validation approach to choose the best model (select the best lambda)
```{r}
set.seed(1234)
lasso_cv <- cv.glmnet(x, y, alpha = 1, nfolds = 10, lambda = lambda_ridge_grid)

lasso_cv$cvm  # the mean cross-validated error (per every lambda)
lasso_cv$cvsd  # estimate of standard deviation error of cvm
lasso_cv$lambda.min  # value of lambda that gives the minimum cvm

lassoreg_2 <- glmnet(x, y, alpha = 1, lambda = lasso_cv$lambda.min)
coef(lassoreg_2)  # coefficients of regression with best lambda value
```

## Model 7: Decision Tree
```{r}
tree_1 <- rpart(Log_Salary ~ Years + Hits + League, data = train, cp = 0.1, maxdepth = 3)
plot(tree_1)
rpart.plot::prp(tree_1)  # plot the tree
tree_1

tree_2 <- rpart(Log_Salary ~ Years + Hits + League, data = train, cp = 0.001, maxdepth = 3)
plot(tree_2)
rpart.plot::prp(tree_2)
tree_2
```

Which cp gives minimum Errors in Train dataset?
```{r}
plotcp(tree_2)
tree_2$cptable
tree_2$cptable[which.min(tree_2$cptable[,'xerror'])]
```

Prune the complex Tree
```{r}
tree_3 <- prune.rpart(tree_2, cp = tree_2$cptable[which.min(tree_2$cptable[,'xerror'])])  # prune tree_2 base on cp being equal to 0.0173088
prp(tree_3)  # plot the pruned tree

tree_4 <- rpart(formula = Log_Salary ~ . - Salary, data = train, cp = 0.0001, maxdepth = 20)  # Decision Tree model using all variables
plot(tree_4)
prp(tree_4)
tree_4
```

Which cp gives minimum Errors in Train dataset?
```{r}
plotcp(tree_4)
tree_4$cptable
tree_4$cptable[which.min(tree_4$cptable[,'xerror'])]
```

Prune the complex Tree
```{r}
tree_5 <- prune.rpart(tree_4, cp = tree_4$cptable[which.min(tree_4$cptable[,'xerror'])])  # prune tree_4 base on optimum cp
plot(tree_5)
prp(tree_5)
tree_5
```

## Model 8: Bagging
```{r}
set.seed(1234)
bagging_1 <- randomForest(Log_Salary ~ . - Salary, mtry = ncol(train) - 2, ntree = 500, data = train)

bagging_1
```

* Each Tree uses 18 variables
* Makes 500 different Trees
* MSE: 0.193834
* R^2^: 0.7657 (76.57% of variance has been explained by this model)

## Model 9: Random Forest
```{r}
set.seed(1234)
rf_1 <- randomForest(Log_Salary ~ . - Salary, data = train, mtry = 6, ntree = 500, importance = T)

rf_1
```

* Each Tree uses 6 variables
* 500 different Trees have been made
* R^2^: 0.7777 (77.77% of variance has been explained by this model)

```{r}
importance(rf_1)
varImpPlot(rf_1)
```

> **CAtBat** has the most impact on increasing MSE if we remove it from the model -> the most important variable

k-fold cross-validation for feature selection
```{r}
set.seed(12345)
rf_cv <- rfcv(train[, -c(18, 20)], train$Log_Salary, cv.fold = 10, step = 0.75, mtry = function(p) max(1, floor(sqrt(p))), recursive = F)
class(rf_cv)
str(rf_cv)

rf_cv$n.var  # vector of number of variables of 'Variables Pool' at each step
rf_cv$error.cv  # vector of MSEs at each step by each 'Variables Pool'
which.min(rf_cv$error.cv)
```

> best 'Variables Pool' has 10 variables

Remove 8 less important variables base on 'relative importance-variables table'
```{r}
sort(importance(rf_1)[,1], decreasing = T)
varImpPlot(rf_1)

reg_formula <- as.formula(Log_Salary ~ CAtBat + CHits + CRuns + Hits + Years + CRBI + Runs + CWalks + CHmRun + Walks)  # pool of 10 main important variables

floor(sqrt(10))  # use maximum 3 variable for every tree in RandomForest
```

Make the optimum model base on k-fold result
```{r}
set.seed(1234)
rf_2 <- randomForest(reg_formula, data = train, mtry = floor(sqrt(10)), ntree = 500)
rf_2
```

> R^2^: 0.7876 (78.76% of variance has been explained by this model)


# Model Evaluation
## Test the Model 5 performance

### Prediction
Create model matrix for Test dataset
```{r}
test$Log_Salary <- log(test$Salary)

x_test <- model.matrix(Log_Salary ~ . - Salary, data = test)[,-1]  # remove intercept

pred_ridgereg <- predict(ridgereg_2, s = ridge_cv$lambda.min, newx = x_test)  # prediction on test dataset
pred_ridgereg  # predictions of Log_Salary
pred_ridgereg <- exp(pred_ridgereg)
pred_ridgereg  # predictions of Salary
```

### Evaluate model performance in Test dataset:
Actual vs. Prediction
```{r}
plot(test$Salary, pred_ridgereg, xlab = "Actual", ylab = "Prediction")
abline(a = 0, b = 1, col = "red", lwd = 2)  # compare with 45' line
```

Absolute Error mean, median, sd, max, min
```{r}
abs_err_ridgereg <- abs(pred_ridgereg - test$Salary) #absolute value (AEV)

hist(abs_err_ridgereg, breaks = 25)  # residuals distribution
mean(abs_err_ridgereg)
median(abs_err_ridgereg)
sd(abs_err_ridgereg)
max(abs_err_ridgereg)
min(abs_err_ridgereg)
```

Boxplot (which observations are outliers?)
```{r}
boxplot(abs_err_ridgereg, main = 'Error distribution')

models_comp <- rbind(models_comp, "RidgeReg" = c(mean(abs_err_ridgereg),
                                                 median(abs_err_ridgereg),
                                                 sd(abs_err_ridgereg),
                                                 IQR(abs_err_ridgereg),
                                                 range(abs_err_ridgereg))) 

models_comp
```

## Test the Model 6 performance
### Prediction
```{r}
pred_lassoreg <- predict(lassoreg_2, s = lasso_cv$lambda.min, newx = x_test)  # prediction on test dataset
pred_lassoreg  # predictions of Log_Salary
pred_lassoreg <- exp(pred_lassoreg)
pred_lassoreg  # predictions of Salary
```

### Evaluate model performance in Test dataset:
Actual vs. Prediction
```{r}
plot(test$Salary, pred_lassoreg, xlab = "Actual", ylab = "Prediction")
abline(a = 0, b = 1, col = "red", lwd = 2)  # compare with 45' line
```

Absolute Error mean, median, sd, max, min
```{r}
abs_err_lassoreg <- abs(pred_lassoreg - test$Salary) #absolute value (AEV)

hist(abs_err_lassoreg, breaks = 25)  # residuals distribution
mean(abs_err_lassoreg)
median(abs_err_lassoreg)
sd(abs_err_lassoreg)
max(abs_err_lassoreg)
min(abs_err_lassoreg)
```

Boxplot (which observations are outliers?)
```{r}
boxplot(abs_err_lassoreg, main = 'Error distribution')

models_comp <- rbind(models_comp, "LassoReg" = c(mean(abs_err_lassoreg),
                                                 median(abs_err_lassoreg),
                                                 sd(abs_err_lassoreg),
                                                 IQR(abs_err_lassoreg),
                                                 range(abs_err_lassoreg))) 

models_comp
```

## Test the Model 7 performance
### Prediction
```{r}
pred_tree <- predict(tree_5, test)  # prediction on test dataset
pred_tree  # predictions of Log_Salary
pred_tree <- exp(pred_tree)
pred_tree  # predictions of Salary
```

### Evaluate model performance in Test dataset:
Actual vs. Prediction
```{r}
plot(test$Salary, pred_tree, xlab = "Actual", ylab = "Prediction")
abline(a = 0, b = 1, col = "red", lwd = 2)  # compare with 45' line
```

Absolute Error mean, median, sd, max, min
```{r}
abs_err_tree <- abs(pred_tree - test$Salary) #absolute value (AEV)

hist(abs_err_tree, breaks = 25)  # residuals distribution
mean(abs_err_tree)
median(abs_err_tree)
sd(abs_err_tree)
max(abs_err_tree)
min(abs_err_tree)
```

Boxplot (which observations are outliers?)
```{r}
boxplot(abs_err_tree, main = 'Error distribution')

models_comp <- rbind(models_comp, "Tree" = c(mean(abs_err_tree),
                                                 median(abs_err_tree),
                                                 sd(abs_err_tree),
                                                 IQR(abs_err_tree),
                                                 range(abs_err_tree))) 

models_comp
```

## Test the Model 8 performance
### Prediction
```{r}
pred_bagging <- predict(tree_5, test)  # prediction on test dataset
pred_bagging  # predictions of Log_Salary
pred_bagging <- exp(pred_bagging)
pred_bagging  # predictions of Salary
```

### Evaluate model performance in Test dataset:
Actual vs. Prediction
```{r}
plot(test$Salary, pred_bagging, xlab = "Actual", ylab = "Prediction")
abline(a = 0, b = 1, col = "red", lwd = 2)  # compare with 45' line
```

Absolute Error mean, median, sd, max, min
```{r}
abs_err_bagging <- abs(pred_bagging - test$Salary) #absolute value (AEV)

hist(abs_err_bagging, breaks = 25)  # residuals distribution
mean(abs_err_bagging)
median(abs_err_bagging)
sd(abs_err_bagging)
max(abs_err_bagging)
min(abs_err_bagging)
```

Boxplot (which observations are outliers?)
```{r}
boxplot(abs_err_bagging, main = 'Error distribution')

models_comp <- rbind(models_comp, "Bagging" = c(mean(abs_err_bagging),
                                                 median(abs_err_bagging),
                                                 sd(abs_err_bagging),
                                                 IQR(abs_err_bagging),
                                                 range(abs_err_bagging))) 

models_comp
```

## Test the Model 9 performance
### Prediction
```{r}
pred_rf <- predict(tree_5, test)  # prediction on test dataset
pred_rf  # predictions of Log_Salary
pred_rf <- exp(pred_rf)
pred_rf  # predictions of Salary
```

### Evaluate model performance in Test dataset:
Actual vs. Prediction
```{r}
plot(test$Salary, pred_rf, xlab = "Actual", ylab = "Prediction")
abline(a = 0, b = 1, col = "red", lwd = 2)  # compare with 45' line
```

Absolute Error mean, median, sd, max, min
```{r}
abs_err_rf <- abs(pred_rf - test$Salary) #absolute value (AEV)

hist(abs_err_rf, breaks = 25)  # residuals distribution
mean(abs_err_rf)
median(abs_err_rf)
sd(abs_err_rf)
max(abs_err_rf)
min(abs_err_rf)
```

Boxplot (which observations are outliers?)
```{r}
boxplot(abs_err_rf, main = 'Error distribution')

models_comp <- rbind(models_comp, "RandomForest" = c(mean(abs_err_rf),
                                                 median(abs_err_rf),
                                                 sd(abs_err_rf),
                                                 IQR(abs_err_rf),
                                                 range(abs_err_rf))) 

models_comp
```

***

For more information check the [Github](https://github.com/mamomen1996/R_CS_05) repository.